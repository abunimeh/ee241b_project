There are five major steps in our methodology(Figure~\ref{fig:tool_flow}).
First, the \emph{signal selection} step walks the circuit graph in FIRRTL\cite{Li:EECS-2016-9}
and picks important signal candidates according to the circuit topology. 
Next, the \emph{power model construct and training} step builds a power model 
using selected signals and trains the model using preliminary
waveforms from small workloads. The \emph{RTL instrumentation} step automatically
instrument the FPGA performance simulators generated by Strober~\cite{Kim2016} with 
the signal activity counters. The \emph{power prediction} step computes
the power dissipation in real time during FPGA performance simulation.
Finally, the \emph{power validation} step validates the power models by
comparing against the power estimation from Strober,
and further trains the power models if necessary.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{images/tool_flow.pdf}
	\caption{Overall Tool Flow}
	\label{fig:tool_flow}
\end{figure}

\subsection{Signal Selection}
\label{sec:signal_selection}

To construct and train a power model, we should select a subset of signals
because it is infeasible to keep track of all signal activities on the FPGA.

There are several observations to select power-sensitive signals. First of all,
\emph{the signal activities of the whole design are driven by the inputs and 
the state of the design.} Thus, we may be able to build an accurate power
model in terms of the register and input toggles. However, there are
a large number of registers in complex hardware designs, and thus,
this is still infeasible for the FPGA.

Fortunately, it seems that \emph{there are only a small number of signal activities
or/and high-level events that drive the state transitions of the design}.
Otherwise, all power estimation methods based on event counters~\cite{Bellosa2000,
Bircher2003, Isci2003,Bircher2005, Bircher2007, Bertran2013} do not make sense.
Therefore, we may be able to construct an accurate power model by using only
a small number of signals that approximate high-level performance / power events.

Figure~\ref{fig:signal_selection} describes how power sensitive signals
are selected. First of all, a random RTL design is fed into the FIRRTL compiler.
In this paper, we assume this design is written with Chisel~\cite{Bachrach2012}.
However, the target designs are not necessarily developed with Chisel
because the FIRRTL compiler will support various languages including Verilog in the near future.

In the FIRRTL compiler, a circuit graph is expressed with an intermediate representation,
FIRRTL~\cite{Li:EECS-2016-9}, so that a designer can write custom compiler passes for their
design. A signal analysis pass is implemented, which examines all write enable signals
for registers. For SRAMs, their write enable signals and read data busses are selected.
The selected signals and busses are dumped to the file used for
power model training in Section~\ref{sec:power_modeling}.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.35\textwidth,height=\textheight,keepaspectratio]{images/signal_selection.pdf}
	\caption{Signal Selection}
	\label{fig:signal_selection}
\end{figure}

\subsection{Power Modeling and Training}
\label{sec:power_modeling}
Once the signals and busses are selected from the previous step, 
a design-specific activity-based power model can be constructed.
Figure~\ref{fig:power_modeling} explains how power models are built and trained.
First, an RTL design is fed into the logic synthesis tool
(e.g. Synopsys Design Compiler~\textregistered) and the place-and-route tool
(e.g. Synopsys IC Compiler~\textregistered) to obtain a gate-level design,
which is simulated in SDF back-annotated gate-level simulation
(e.g. Synopsys VCS~\textregistered) for accurate power estimates
by the power analysis tool(e.g. Synopsys PrimeTime PX~\textregistered).

RTL signal activities are also computed from RTL simulation(e.g. Verilator, Synopsys VCS~\textregistered).
By providing the signal list, the RTL signal activities, and the detailed power estimates
to the power modeling and training algorithm, a design-specific power model can be constructed
expressed with the signal toggle activities.

For RTL simulation and gate-level simulation, microbenchmarks or random instruction streams are employed
for initial power model training. In addition, there can be random execution sample snapshots from
long-running FPGA performance simulation~\cite{Kim2016}, which are used not only for power model validation
but also for further training the power model for more accurate power estimates.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{images/power_modeling.pdf}
	\caption{Power Modeling and Training}
	\label{fig:power_modeling}
\end{figure}

\subsubsection{Macromodels for Complex Combinational Logic}
Previous work~\cite{Sunwoo2010} suggests that linear power models for complex combinational logic such as ALUs, SEC/DED circuits, interrupt controllers, and multipliers are inaccurate. To overcome this issue, we turn to macromodels which attempt to estimate the power of complex logic by only looking at the input and output switching activity of the combinational block. In this paper we will measure the accuracy of a previously proposed power macromodel that uses 4 statistics $P_{in}, D_{in}, SC_{in}, D_{out}$.~\cite{Najm2000}\cite{Najm2000_2}

This macromodel considers sequences of input vectors into a combinational block. Each sequence may contain $N$ input vectors. Then we can define for a given sequence,
\begin{itemize}
	\item $P_{in}$ = average number of input bits that are logic 1 across a sequence
	\item $D_{in}$ = average number of input bit transitions across a sequence (average input transition density)
	\item $SC_{in}$ = average spacial correlation coefficient across a sequence and across all input bit pairs
	\item $D_{out}$ = average number of output bit transitions across a sequence (average output transition density)
\end{itemize}

In the context of power estimation for a large digital design: if a complex combinational block is detected in the design, the power macromodel will be used in place of a linear model. To feed the macromodel with data, the combinational block's inputs and outputs will be instrumented. A small logic block on the FPGA will map the raw input and output signals into a 4-tuple that represents the above statistics, and the tuple will be fed out of the FPGA emulator to be plugged into the power macromodel.

\subsection{RTL Instrumentation}
\label{sec:instrumentation}
The RTL instrumentation is built upon the Chisel3 and FIRRTL port of the Strober's flow
to generate FPGA performance simulators. Figure~\ref{fig:power_modeling} shows how
the FPGA performance simulators are instrumented with the signal activity counters.

First, the target RTL design is FAME1-transformed to create the FPGA performance simulator~\cite{Kim2016}
in the FIRRTL compiler. Then, a custom transform is executed to attach activity counters
to the FPGA performance simulator by using the signal list from Section~\ref{sec:signal_selection}.
In addition, scan chains are inserted not only to read out the activity counter values but also to
capture RTL state snapshots to validate the power model. Finally, simulation mapping and platform mapping
are conducted for FPGA simulation~\cite{Kim2016}.

Note that signal selection in Section~\ref{sec:signal_selection} can be integrated to
this flow if signals are not pruned during power modeling and training in
Section~\ref{sec:power_modeling}. In this case, FPGA simulation can run in parallel while
training power models, which uses slow CAD tools extensively.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{images/instrumentation.pdf}
	\caption{Power Modeling and Training}
	\label{fig:power_modeling}
\end{figure}

\subsection{Power Prediction during FPGA Simulation}
\label{sec:power_prediction}
Once the FPGA performance simulator instrumented with activity counters is obtained,
power estimates are quickly available during FPGA simulation. Since the target RTL
is FAME1-transformed, FPGA simulation can be easily paused, and activity counter
values are read out from the FPGA in the same way random RTL state sample snapnots
are taken in Strober~\cite{Kim2016}. If the power model is not available during
FPGA simulation because it is still trained, the activity counter values are saved
to estimate the power dissipation later.

\subsection{Power Validation}
\label{sec:power_validation}
Designers may want to validate the power estimates from Section~\ref{sec:power_prediction}
after FPGA simulation. Since this methodology is combined with Strober,
an accurate power estimates with statistically bounded errors are available by
replaying random RTL state snapshots, which are used to further train the power model
for more accurate power estimates (Figure~\ref{fig:power_modeling}).
